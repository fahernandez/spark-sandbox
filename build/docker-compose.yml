version: "3.7"
services:
  data_analysis_python:
    build:
      context: .
      dockerfile: Dockerfile-python
    image: data_analysis_python:1.0.0
    container_name: data_analysis_python
    volumes:
      - ../python/:/home/data-analysis
      - ../data:/home/data-analysis/data
    working_dir: /home/data-analysis
    ports:
      - 8888:8888
    environment:
      - TARGET=LIVE
      - JUPYTER_ENABLE_LAB=yes
      - CHOWN_HOME=yes
      - NB_UID=1000
      - NB_USER=data-analysis
    user: root
    init: true
    networks:
      - data-analysis
  data_analysis_r:
    build:
      context: .
      dockerfile: Dockerfile-r
    image: data_analysis_r:1.0.0
    ports:
      - "8787:8787"
      - "8088:8088"
    environment:
      - PASSWORD=admin
      - NB_UID=1000
      - NB_USER=data-analysis
    volumes:
      - ../r/:/home/rstudio
      - ../data:/home/rstudio/data
    working_dir: /home/rstudio
    user: root
    init: true
    networks:
      - data-analysis
  spark-master:
    image: bde2020/spark-master:3.1.1-hadoop3.2
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    networks:
      - data-analysis
  spark-worker-1:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    networks:
      - data-analysis
networks:
  data-analysis:
      name: data-analysis
